{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "untrainedCNNWithImageAug.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGXEL3DkrSwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hItbh2TFxeet",
        "colab_type": "code",
        "outputId": "83476c16-48df-4617-9523-c2b7d52611cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL04ceUmyqXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "5fbd4d1d-ef7d-4b07-9871-23280a7d1e01"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "import cv2\n",
        "from random import shuffle\n",
        "from shutil import copyfile,rmtree\n",
        "import json\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class ImagePrep:\n",
        "    \n",
        "    def getTrainTest(self,directory,extention):\n",
        "        files = []\n",
        "        for file in os.listdir(directory):\n",
        "            if file.endswith(extention):\n",
        "                files.append(file)\n",
        "        shuffle(files)\n",
        "        splt = int(len(files)*0.8)\n",
        "        x_train_files = files[0:splt]\n",
        "        x_test_files = files[splt:-1]\n",
        "        \n",
        "        json_data = open(directory +'/calories_json.json',mode='r').read()\n",
        "        y_map = json.loads(json_data)\n",
        "        \n",
        "        x_train = [load_img(directory+\"/\"+x, target_size=(224,224,3)) for x in x_train_files]\n",
        "        y_train = [y_map[x] for x in x_train_files]\n",
        "        x_test = [load_img(directory+\"/\"+x, target_size=(224,224,3)) for x in x_test_files]\n",
        "        y_test = [y_map[x] for x in x_test_files]\n",
        "        \n",
        "        return x_train,y_train,x_test,y_test\n",
        "    \n",
        "    def augmentImages(self,x,y):\n",
        "        x_train_aug = []\n",
        "        y_train_aug = []\n",
        "        \n",
        "        for i in range(len(x)):\n",
        "            x_train_aug.append(x[i])\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "            #transformation one - adding random black dots in the image\n",
        "            t = iaa.CoarseDropout(0.1, size_percent=0.2).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "            #transformation two - simple rotation\n",
        "            t = iaa.Affine(rotate=(-25, 25)).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "        \n",
        "            #transformation three - increasing the contrast of the objects in the image\n",
        "            t = iaa.GammaContrast(1.5).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "            #transformation four - mirror effect\n",
        "            t = iaa.Fliplr(p = 1.0).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "            #transformation five - blurring effect\n",
        "            t = iaa.GaussianBlur((0, 3.0)).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "            #transformation six - cropping and padding, expand, squish, move effect\n",
        "            t = iaa.CropAndPad(percent=(-0.25, 0.25)).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "            #transformation seven - it randomly moves pixels around within a given bound\n",
        "            t = iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25).augment_images([np.array(x[i])])\n",
        "            x_train_aug.append(Image.fromarray(np.uint8(t[0])))\n",
        "            y_train_aug.append(y[i])\n",
        "            \n",
        "        return x_train_aug,y_train_aug"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-r_mzZCy50o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj = ImagePrep()\n",
        "x_train,y_train,x_test,y_test = obj.getTrainTest(\"drive/My Drive/subway\",'.png')\n",
        "x_train_aug,y_train_aug = obj.augmentImages(x_train,y_train)\n",
        "\n",
        "x_train_aug_np = np.array([np.array(x) for x in x_train_aug])\n",
        "y_train_aug = np.array(y_train_aug).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSSLSr7O-S1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import mean_squared_error as mse\n",
        "from keras import layers,models\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "class Models:\n",
        "\n",
        "    def cnn(\n",
        "        self,\n",
        "        width,\n",
        "        height,\n",
        "        depth,\n",
        "        filters=(16, 32, 64),\n",
        "        regress=False,\n",
        "        ):\n",
        "\n",
        "        # initialize the input shape and channel dimension, assuming\n",
        "        # TensorFlow/channels-last ordering\n",
        "\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # define the model input\n",
        "\n",
        "        inputs = Input(shape=inputShape)\n",
        "\n",
        "        # loop over the number of filters\n",
        "\n",
        "        for (i, f) in enumerate(filters):\n",
        "\n",
        "            # if this is the first CONV layer then set the input\n",
        "            # appropriately\n",
        "\n",
        "            if i == 0:\n",
        "                x = inputs\n",
        "\n",
        "            # CONV => RELU => BN => POOL\n",
        "\n",
        "            x = Conv2D(f, (3, 3), padding='same')(x)\n",
        "            x = Activation('relu')(x)\n",
        "            x = BatchNormalization(axis=chanDim)(x)\n",
        "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "            # flatten the volume, then FC => RELU => BN => DROPOUT\n",
        "\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(16)(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = BatchNormalization(axis=chanDim)(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "\n",
        "        # apply another FC layer, this one to match the number of nodes\n",
        "        # coming out of the MLP\n",
        "\n",
        "        x = Dense(4)(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        # check to see if the regression node should be added\n",
        "\n",
        "        if regress:\n",
        "            x = Dense(1, activation='linear')(x)\n",
        "\n",
        "        # construct the CNN\n",
        "\n",
        "        model = Model(inputs, x)\n",
        "\n",
        "        # return the CNN\n",
        "\n",
        "        return model\n",
        "\n",
        "    def resnet(self, freezing):\n",
        "        resnet50_model = ResNet50(include_top=True, weights='imagenet')\n",
        "\n",
        "        # in this model we are freezing layers(3,116) inclusive freezing\n",
        "\n",
        "        if freezing:\n",
        "            times = 0\n",
        "        for i in range(3, 200, 1):\n",
        "            if 'BatchNormalization' \\\n",
        "                in str(type(resnet50_model.layers[i])) and times == 40:\n",
        "                break\n",
        "            else:\n",
        "                if 'BatchNormalization' \\\n",
        "                    in str(type(resnet50_model.layers[i])):\n",
        "                    times += 1\n",
        "            resnet50_model.layers[i].trainable = False\n",
        "        regression_model = models.Sequential()\n",
        "        resnet50_model.layers[176] = layers.Dense(512, activation='relu'\n",
        "                )\n",
        "        regression_model.add(resnet50_model)\n",
        "        regression_model.add(layers.Dense(256, activation='sigmoid'))\n",
        "        regression_model.add(layers.Dense(128, activation='relu'))\n",
        "        regression_model.add(layers.Dense(1, activation='linear'))\n",
        "        regression_model.compile(optimizer='sgd',\n",
        "                                 loss='mean_squared_error',\n",
        "                                 metrics=['accuracy'])\n",
        "        return regression_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbYuTFJY1aCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "f6ae1616-9ef5-4426-982a-1ecaf39ee40c"
      },
      "source": [
        "models = Models()\n",
        "cnn_model = models.cnn(224,224,3,regress=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKpOg9mf1dqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ca6cb3ad-6631-4cfd-f51f-e7bd8c6e793c"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "cnn_model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar3DYncK9EO9",
        "colab_type": "code",
        "outputId": "d4d06bc5-06c0-4f72-869c-bb5f7d107fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnn_model.fit(x_train_aug_np, y_train_aug, epochs=30, batch_size=8)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "960/960 [==============================] - 8s 8ms/step - loss: 99.7085\n",
            "Epoch 2/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 98.8013\n",
            "Epoch 3/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 97.0321\n",
            "Epoch 4/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 93.9480\n",
            "Epoch 5/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 88.3963\n",
            "Epoch 6/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 81.4801\n",
            "Epoch 7/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 73.7836\n",
            "Epoch 8/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 67.5891\n",
            "Epoch 9/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 62.1036\n",
            "Epoch 10/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 57.0451\n",
            "Epoch 11/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 56.3206\n",
            "Epoch 12/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 53.6574\n",
            "Epoch 13/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 49.3382\n",
            "Epoch 14/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 45.1162\n",
            "Epoch 15/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 41.6096\n",
            "Epoch 16/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 40.1060\n",
            "Epoch 17/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 38.4067\n",
            "Epoch 18/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 36.7226\n",
            "Epoch 19/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 36.1290\n",
            "Epoch 20/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 35.1849\n",
            "Epoch 21/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 34.7959\n",
            "Epoch 22/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 34.9638\n",
            "Epoch 23/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 33.3535\n",
            "Epoch 24/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 33.7113\n",
            "Epoch 25/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 33.1371\n",
            "Epoch 26/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 33.0180\n",
            "Epoch 27/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 32.2224\n",
            "Epoch 28/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 31.3954\n",
            "Epoch 29/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 32.4077\n",
            "Epoch 30/30\n",
            "960/960 [==============================] - 4s 4ms/step - loss: 34.0932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27a249f860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyupN4ta90km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_np = np.array([np.array(x) for x in x_test])\n",
        "y_pred = cnn_model.predict(x_test_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6aw71YB99zo",
        "colab_type": "code",
        "outputId": "7da02488-dea7-4b8d-dc07-13572dbe46a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "y_test_np = np.array(y_test).astype('int')\n",
        "print(np.average(y_pred.flatten() - y_test_np))\n",
        "print(y_pred.flatten())\n",
        "print(y_test_np)\n",
        "print(y_test_np-y_pred.flatten())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-168.14737590154013\n",
            "[570.0415    391.2285    299.49963   537.54987   229.06223   271.21716\n",
            " 253.16357     1.8840995 340.79242   634.80237   480.06262   348.58014\n",
            " 273.40656   288.07565   400.26498   532.8608    250.59332   330.68503\n",
            " 411.7417    298.6304    242.15988   242.38947    91.19758   396.48895\n",
            " 269.41028   183.61203   294.36942     1.8840995 556.5113    430.4132   ]\n",
            "[ 950  370  330  887  400  370  220  390  570 1200  300  300  140  480\n",
            "  750  600  500  680  840  380  380  350  420  630  360  430  270  280\n",
            "  700  420]\n",
            "[ 379.95849609  -21.22848511   30.50036621  349.45013428  170.93777466\n",
            "   98.78283691  -33.16357422  388.11590052  229.20758057  565.19763184\n",
            " -180.06262207  -48.58013916 -133.40655518  191.92434692  349.73501587\n",
            "   67.13922119  249.40667725  349.31497192  428.25830078   81.36959839\n",
            "  137.84011841  107.61053467  328.80242157  233.51104736   90.58972168\n",
            "  246.38796997  -24.36941528  278.11590052  143.4887085   -10.41320801]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKUxSunArOxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a3a61f32-e7e4-4eaa-8c8f-cc9ded322892"
      },
      "source": [
        "pip uninstall tensorflow"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjqQdk0yrSJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "03d8825c-0263-44e0-8ba6-a06959d565c1"
      },
      "source": [
        "pip install tensorflow==1.12\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 118kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.8.1)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.17.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (41.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lymNhDGSqXwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "40699c99-213b-4a39-a872-a27b94bd0f6a"
      },
      "source": [
        "from tensorflow import lite\n",
        "\n",
        "cnn_model.save('cnn_untrained_30ep_8b_adam_burgers.h5')\n",
        "converter = lite.TFLiteConverter.from_keras_model_file('cnn_untrained_30ep_8b_adam_burgers.h5')\n",
        "converter.allow_custom_ops = True\n",
        "tfmodel = converter.convert()\n",
        "open(\"model.tflite\",\"wb\").write(tfmodel)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Froze 28 variables.\n",
            "INFO:tensorflow:Converted 28 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3314092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4IQ8r_40RvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pickle\n",
        "#filename = 'cnn_untrained_30ep_8b_adam.sav'\n",
        "#pickle.dump(cnn_model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vdKR8rX2_29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from flask import Flask, jsonify, request, render_template"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Y5x1Si3Rr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#app = Flask(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw2WmZrz3pNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL = pickle.load(open('cnn_untrained_30ep_8b_adam.sav', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVzt02wK3smK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@app.route('/api', methods=['GET'])\n",
        "#def api():\n",
        "#    \"\"\"Handle request and output model score in json format.\"\"\"\n",
        "   # Handle empty requests.\n",
        "#    if not request.json:\n",
        "#        return jsonify({'error': 'no request received'})\n",
        "    # Parse request args into feature array for prediction.\n",
        " #   np_array_input = parse_args(request.json)\n",
        "    # Predict on x_array and return JSON response.\n",
        "#    estimate = int(MODEL.predict(np_array_input)[0])\n",
        "#    return estimate\n",
        "\n",
        "#def parse_args(json):\n",
        "#    inp = json.get(\"file\")\n",
        "#    img = load_img(inp, target_size=(224,224,3))\n",
        "#    return np.array(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_-QlVr394gF",
        "colab_type": "code",
        "outputId": "5d3bb468-8915-4e27-8a0b-0ff9a496ec51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#if __name__ == '__main__':\n",
        "#    app.run(host='0.0.0.0', port=5000, debug=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: on\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
            " * Restarting with stat\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFC8RD93-F_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#exit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RgbW0aQ-NRg",
        "colab_type": "code",
        "outputId": "79ab0752-8679-4e0f-d78c-9129078047a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#f = \"drive/My Drive/subway/bk_660.png\"\n",
        "#img = load_img(f, target_size=(224,224,3))\n",
        "#test = np.array([np.array(img)])\n",
        "#MODEL.predict(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[562.79755]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQm169VGLSVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}